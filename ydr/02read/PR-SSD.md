## 总结
### Key insight
- SSD具有部分读特性，16KB的大页可以只读4KB
- 不压缩没法利用这个特性，所以要压缩
- 然而现有压缩的时延太大了
- 决定自己设计一套解压缩时延很低的压缩算法
- 同时充分实现了部分读的channel并行

### Key design
- 可压缩数据：借鉴内存压缩算法，修改了诸如粒度（32->1024）等做了改进得到了DPC
- 不可压缩数据：拆分到不同并行单元

### DPC key design
- 粒度 下32-1024B粒度下主导模式接近50%，针对主导模式压缩
- 全零页不写入（见招拆招，不常见）
- 针对主导模式的压缩（还没看）


### split key design
- 将写请求按照4KB的粒度拆分到不同的channel，以支持部分读的并行
（原来的写请求是按照16KB粒度拆分到不同的channel）



## 问题

**压缩有关**

Q1（1）：为什么压缩要在SSD层面做，为什么不能在其他层级（例如：文件系统层级，块设备层，上层应用自己做）做？

Q1（2）：全文一直在讨论现有的压缩解压缩速度太慢？有没有具体的数据表示有多慢，一个I/O路径下，压缩/解压缩和读取的占比占多少？

**碎片化问题**

Q2（1）：不可压缩率到底是怎么评估的？是16KB压缩不到4KB就算不可压缩吗？
Q2（2）：众所周知，压缩的后数据的长度是变长的，16KB压缩后可能小于4KB，可能大于4KB，而部分读只能读4KB，它是怎么处理这个问题的？

**部分读特性上**

Q3：我注意到测试部分有一个对比对象是host端，什么也不做也能利用部分读。我想问为什么不压缩也能利用这一个特性？也就是为什么一定要用它的压缩呢？

**channel并行**

Q4（1）：顺序读条件下，这个优化效果是不是没有？只能优化随机读？
Q4（2）：牺牲写入的性能来对读性能做优化是否可行？
Q4（3）：智能拆分有多智能，能完全屏蔽负优化吗，带来的开销有多大，值得吗？

