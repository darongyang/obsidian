

上一次的分享，我讨论了云存储中的闪存缓存。今天，我将继续围绕闪存缓存的主题，但这次关注的是数据中心中的闪存缓存。我今天要分享的这篇论文名为《FairyWREN》，是由卡内基梅隆大学（CMU）团队和微软公司合作，发表在今年的计算机系统顶会 _OSDI_ 上。这篇论文提出了一种用于新兴写-读-擦除闪存接口的可持续缓存方案。

我的分享将从以下几个方面展开：背景、动机、设计、测试以及总结。

## 背景

近年来，碳排放和碳减排问题越来越受到关注。数据中心的碳排放占据了全球总碳排放中的重要份额。根据论文的数据，预计到2050年，数据中心的碳排放将占全球总碳排放的33%以上。为了应对这一挑战，像亚马逊、谷歌、Meta、微软等大公司都在积极寻求实现碳的净零排放。根据《2030数据中心白皮书》，零碳节能已经成为未来数据中心的一个重要目标。

借用作者在OSDI演讲中使用的一张图，我们可以看到，数据中心的碳排放主要分为两类：运营碳排放和隐含碳排放。运营碳排放相对容易控制，比如通过使用太阳能、风能等可再生能源。然而，隐含碳排放则相对较难，逐渐占据了主导地位，达到了80%以上。隐含碳排放主要来源于数据中心基础设施的生产、运输、功耗和最终报废，根本原因在于硬件设备的生命周期。

了解了数据中心的碳减排后，我们再来看数据中心的存储系统。存储是数据中心的核心任务之一。现在主流的存储器件主要是两类：HDD，俗称的机械硬盘。SSD，俗称的固态硬盘，又叫做闪存存储，因为基于闪存介质。内存则通常使用DRAM。不同层级的存储器件，其速度和成本不同。通常来说，如表中所示，内存DRAM的成本大于固态硬盘SSD，大于机械硬盘HDD，均差一个数量级。在大规模的数据中心中，缓存不会全部使用DRAM，存储也不会全部使用SSD，而是采用折衷的闪存缓存的存储体系。中间的结构被称为“闪存缓存”，它连接了主存和二级存储。

## 动机

在动机上。使用闪存缓存有一个很好的优势：碳减排。内存和存储通常占据服务器碳排放的46%和40%。相比用DRAM做缓存，闪存缓存具备更低的功耗，能够减少高达12x的隐含碳排放。此外，近年来，此外，闪存技术近几年也在朝着更高密度的发展。一个存储单元从原来只能存储1比特，也就是SLC，发展到现在能够存储4比特，也就是QLC。相同硅片上能够存放更多比特，进一步降低生产成本，减少隐含碳排放。

目前，数据中心通过延长服务器的使用寿命来减少隐含碳排放。这容易达到，微软和meta等公司已经实施。但与之相比，闪存设备则相对困难，其具备非常有限的写入寿命。随着闪存密度的增加，其使用寿命进一步下降。为了达到6年写入寿命，只能限制每日写入量很小。从右图可以看到，纵向看不同颜色的线，使用寿命越长带来的碳排放和成本的模型值越低。从横向看不同的介质，随着存储介质密度的增加，闪存设备每日写入量的限制更加严格。

然而，与每日写入量的严格要求相违背的是，假设不加以精心设计，闪存设备上会存在特别大的写入放大。这是闪存设备的常见问题，体现为写有效数据时，会重复写入很多额外的数据。主要分析其原因包括两种：第一种是应用级写入放大。在闪存中，数据通常按写入单元（例如64KB）进行存储。如果只写入少量数据（例如100字节），那么就会先读取64KB的页面，修改其中的100字节，然后重新写入64KB的页面，导致最多640倍的写入放大。第二种是设备级写入放大。当闪存存储空间满时，设备会进行垃圾回收，将有效数据聚集到一起，然后擦除原来的擦除单元。由于擦除单元的大小通常是GB级别，而写入单元只有64KB，导致有效数据的碎片需要频繁搬迁，进一步加剧了写入放大。如果没有合理的设计，闪存设备将面临严重的写入放大问题，这也是本篇论文所聚焦的核心问题之一。


基于前面的分析，作者提出了设计可持续、低碳排放闪存缓存的三个核心要点：首先，要减少无用的闲置空间，因为闲置空间会直接提高隐含碳成本；其次，需要尽可能减少DRAM的使用，从而降低能耗；最后，要尽量降低写入放大，以减缓设备的磨损速度。与传统的DRAM缓存和键值存储相比，闪存缓存的设计思路更为复杂。DRAM缓存无需考虑寿命问题，而键值存储则缺乏快速删除的能力，这些都使得它们无法直接应用于闪存缓存的设计。

在优化闪存缓存方面，已有多项重要研究成果，且均发表在计算机系统领域的顶级会议上，如OSDI和SOSP。  第一个典型的方案是基于日志结构的闪存缓存。这种方法的核心原理是对缓存对象进行顺序的追加写，同时为每个对象建立一个对应的DRAM索引。顺序写的好处在于能够解决写入放大的问题。然而，当缓存的对象非常小时，DRAM索引的开销会变得极为庞大。例如，要缓存2TB的100字节数据，所需的DRAM索引高达75GB。

第二个是，发表在OSDI'20上的CacheLib。CacheLib采用了组相联缓存的设计，利用哈希函数替换掉了原来的DRAM索引，将每个对象映射到指定的唯一集合内，当集合写满了以后就进行缓存的替换。这样的好处是极大的降低了DRAM索引，但缺点在于带来了小对象的随机写，每次写入一个100B的小对象，都会带来几十倍的写入放大。

第三个是，发表在SOSP'21年的最佳论文Kangaroo。Kangaroo结合了日志结构和组相联缓存的优点，提出了一种分层架构设计。具体而言，它在写入小对象时不急于立即进行哈希操作，而是先通过顺序写实现日志化缓存，随后再以集合为单位执行哈希操作。这种设计在减少应用级写入放大和DRAM索引方面取得了显著效果。然而，Kangaroo的层次设计虽然缓解了小数据与4KB写入单元的失配问题，但与GB级别擦除单元的失配依然存在。这种失配会导致设备级写入放大的问题，仍然难以完全避免。

设备级写入放大的根本原因在于传统的LBAD接口效率低下。LBAD接口最初设计是为了简化从机械硬盘到固态硬盘的过渡，它屏蔽了设备的物理层细节，只暴露逻辑层。像Kangaroo这样的设计，其所有缓存操作，包括缓存的驱逐和替换，都基于逻辑层完成，而设备的垃圾回收则是完全自主的。这种逻辑与物理层的隔离带来了潜在问题。

可以考虑一种较坏的情况：例如，设备刚刚完成一个有效数据块的搬迁，但随后该数据却因缓存替换而失效，从而导致一次无意义的写入。对于密集覆写的缓存场景，这一问题尤为突出。

近年来，新兴的WREN接口（如ZNS、FDP等设备）为解决这一问题提供了新的可能。WREN接口允许上层完全控制写入操作，包括垃圾回收。如右图所示，这种新接口能够显著提升写入的可控性。作者将其规范化为三类关键操作：写入、读取和擦除；同时要求擦除操作必须以整块为单位，并由上层完全控制；此外，设备还需支持多个活跃的擦除单元。基于这一规范化定义，作者在软件层面设计了对应的闪存缓存架构。

近年来，一种新兴的接口：WREN接口出现，例如ZNS、FDP等设备。这种新的WREN接口能够允许上层自主控制所有写入（包括GC）。如右边这张图的直观显示，新兴接口能够为上层提供一种自主的写入控制。作者对这类接口进行规范化定义，在具体操作上，它要包括三类WREN操作，写入-读取-擦除；第二，擦除要求整块擦除并且上层可控；第三，同时存在多个活跃的擦除单元。基于这种规范化定义，作者围绕其展开了软件层的设计，设计了新的闪存缓存。

通过硬件和软件的协同优化，FairyWREN成功实现了可持续闪存缓存的设计目标。


## 实现


在设计上，FairyWREN采用了一种分层的架构。具体而言，它由两个主要模块组成：LOC模块和SOC模块。第一个是LOC模块，用于缓存大于2KB的大对象，初步实现大小对象的分离。LOC通过日志结构实现顺序写入，并在DRAM中建立对象索引。由于对象较大，这个内存开销是可控的。这里的一个关键设计是，为了适配新接口的特性，FairyWREN将缓存段的大小对齐为一个可控的擦除单元。它的缓存插入和缓存查询都较为直接。为了设备级写入放大，本篇工作额外引入了缓存替换逻辑，后面一起介绍。
第二个是SOC模块，用于缓存小于2KB的小对象。小对象不能够采用原先的设计，因为内存开销会很大。SOC做了分层设计：包括DRAM、少量日志结构缓存、大量的组相联缓存。缓存插入会优先插入到高层，再依次驱逐到低层。这里的一个关键设计是，同样为了适配新接口的特性，FairyWREN实现组相连缓存的变体，将Set的随机写变成了顺序追加，同时为每个Set建立内存索引。但这也带来了更多的内存索引开销，作者后续对此进行了相应设计。作者同样对SOC额外引入了缓存替换逻辑。

作者最核心的贡献在于，将传统闪存缓存的替换逻辑、设备的垃圾回收逻辑，原本分割的两者结合在一起，避免了设备层级进行无效的垃圾回收。首先，对于LOC模块，由于其是单层、顺序追加写以及对齐的设计。缓存替换只发生垃圾回收时，只需要通过LRU等方式擦除整个擦除单元即可。而SOC模块，是双层、非对齐的设计，这是论文设计的难点，也是关键点。

SOC采用了嵌套打包的算法，对于双层结构，各自空间满了之后，都会进行垃圾回收。FairyWREN从中选出一个擦除单元进行回收。此处的垃圾回收，并不是传统设备上无效的迁移。相反，闪存缓存会对回收的单元进行分析，选出自己认为有用的Set进行迁移。具体是如何选取有用的Set的？FairyWREN会将EU进行散列，恢复出Set结构。然后会检索上层结构得出哪些Set是需要回收，哪些Set需要进行重组。迁移完上述有用的Set后，FairyWREN擦除原来的单元。总结是，闪存缓存也可以控制垃圾回收，将其缓存替换相结合，避免了无效重复写。

其他设计上，时间限制，我做简单介绍。进行前面的嵌套打包时，有可能只回收一个对象，还是会带来整个Set的写入。我们把经常访问或经常写的特性，叫做热。对此FairyWREN将Set进行了冷热划分，同时将对象也进行了冷热划分。FairyWREN识别出热对象后，将其放到冷SubSet中。这样一来，只需要一直更新热SubSet即可。当然，冷热子集的对象的冷热程度会随插入而发生改变，所以需要定期进行冷热重组。

第三个设计，前面的设计带来了Set的内存索引，而Set的冷热划分，进一步增大了这个索引。如何控制好索引开销，是一个关键的问题。FairyWREN通过切片、共享和双缓冲的方式缓解这个问题。切片散列的方式可以降低索引位数。然而，不可能为每个切片分配一个擦除单元。FairyWREN引入了共享擦除单元的设计。但共享会导致不同切片写满的速度不一样，这会导致写会闪存时的碎片化的问题。FairyWREN进一步引入了双缓冲区的方式，让快的写满后等一下慢的，缓解了这一问题。最终DRAM开销相比SOTA控制在19%以内。

## 测试

在测试上，测试环境配置中，作者基于CacheLib、使用模拟和真实的ZNS设备，基于Meta和推特的Trace进行，并对SSD寿命和碳排放进行了建模。对比对象包括：理想的写入、日志结构缓存、SOTA Kangaroo和Kangaroo简单移植到ZNS的版本，也就是不做额外设计。

从总体的碳排放结果中，可以看到FairyWREN对比SOTA Kangaroo总体排放量减少21.2%，最核心原因在于FairyWREN的闪存碳排放最少。

在磨损速度和性能的测试上，FairyWREN对比SOTA Kangaroo减少了12.5x的写入放大，也就是磨损速度。性能均比Kangaroo要好。并且对于缓存而言，这些优势并没有以牺牲缓存命中率为代价。

作者进一步研究了不同命中率下的影响，对比了直接将Kangaroo搬到新接口的方案，发现FairyWREN接近理想情况，且直接将Kangaroo搬到新接口的优化效果不大。

作者在各种高密度闪存上进行测试分析，认为只有FairyWREN能够运用到高密度闪存QLC和PLC上。具体是哪些技术点带来了这些优势？作者进一步进行分解测试，可以看到嵌套打包和冷热分离两个技术均贡献了多倍的优化。

## 总结

以上是论文的全部内容。下面我对这篇论文进行简单小结。这篇论文主要背景是数据中心的碳排放问题，存储器件的碳排放贡献很大。然而问题是，高密度闪存带来低碳的契机，但其寿命受到严峻挑战。传统的LBAD接口会带来两级写入放大加剧寿命磨损。现有的缓存方案，并不符合可持续使用的要求。机遇是近年来出现了新的WREN接口，围绕其新硬件特性作者对闪存缓存进行了软件设计，最终解决上述的问题。总的来说，在软件设计上，作者的方案是：提出适配到新接口的设计架构、通过嵌套打包算法统一垃圾回收和缓存写入，进一步作者还实现了冷热对象分离和DRAM开销优化，使得系统整体上表现最佳。

本文亮眼之处在于其总结性的写作方法、让人眼前一亮的新背景、以及扎实的建模和实验。作者团体在本次OSDI投稿前，就已经在HotCarbon'24上发表过有关存储器件碳排放建模分析的文章，功底很扎实。论其不足之处，我认为是过于简单的设计，对工作独到之处没有明确，需要读者对比阅读和总结。



















## QA

Q1：从报告中看出，设备级的写入放大，其主要原因是写入单元和擦除单元的失配问题。我想请问，设备级写入放大能否通过减小擦除单元来进行减小或擦除？
A1：一般说来，是软件围绕硬件开展设计。硬件处于这种设计的原因，更多还是出于成本的考虑。作者也有对这个做了一点分析，文章中说到要将擦除单元从GB降低到KB量级才会有效果，然而这在现在硬件实现上几乎是不可行的。所以不能够想当然的这样弥补。

Q2：FairyWREN从碳减排的角度出发，我想问这个工作减少了闪存缓存上的碳排放，有没有增加其他方面的消耗呢，例如CPU上。
A2：作者的核心贡献，是将垃圾回收和缓存驱逐相结合，并没有带来额外上计算上的碳排放开销。确实对于DRAM上会有部分开销，但作者进行了优化，控制了开销程度。最后通过作者的建模，闪存减少的开销弥补了DRAM的开销，并且取得更好效果。


Q3：我想问有关冷热对象分离的问题，第一个是作者是如何识别冷热对象的，以及识别准确度有多少？为什么这个区间多分几份，优化效果就更好？
A3：冷热对象的识别方式不是作者设计的核心，是直接利用的现有的一些算法RRIP，这些常用于处理器判断的算法。针对这个算法准确性没有做太多评估。但作者提到区间的过度划分会导致RRIP算法带来缓存不命中率的增加，因此不宜过多划分。

Q4：正如背景所提到的，闪存缓存是DRAM和HDD的连接器，为什么整篇文章的介绍里，看到了很多和DRAM联合设计的介绍，但没有见到闪存缓存和HDD之间联合设计的内容？
A4：本质是数据的传输在金字塔中是从上到下的单向传输。作者考虑DRAM设计，是因为数据会先经过DRAM，才到闪存缓存。作者的目光只聚焦在闪存缓存，讨论的最深内容仅限于闪存缓存的驱逐操作，因为驱逐下去就和闪存缓存无关了。具体从闪存缓存驱逐出去的数据如何进一步在HDD管理，是下层存储HDD该考虑的事情，不是本文关注的范畴领域。


## 3 设计
Key insight：将垃圾回收和缓存准入进行统一，无论在线写入还是垃圾回收都能够进行对象准入。（换句话说，就是借助WREN让垃圾回收的时候做到object attention，主动判断哪些对象要重写/回收，避免像LBAD那样无效回收）
### 3.1 系统结构
![[Pasted image 20241105000805.png]]
- LOC：缓存大对象（>2KB）
	- DRAM：EU大小的segment buffer + 大对象索引
	- LOC：采用日志化结构缓存，执行大的顺序写。适应到WREN很简单，segment大小定为一个EU即可。由于对象较大，其DRAM开销较小。
	- 两种缓存操作：（1）**插入**。先插入DRAM并建立索引，segment满了一起写闪存。当插入发生替换时，采用GC相结合的设计，见3.2。（2）**查询**。查询查找object的key对应的地址，然后从闪存读取。
- SOC：缓存小对象
	- DRAM：FwLog的segment buffer + FwLog的小对象索引 + FwSet的set索引
	- FwLog：采用日志化结构缓存，缓冲小object以便可以高效写入FwSet。小对象索引DRAM开销大，为了保证其开销，FwLog只占SOC的5%。
	- FwSet：采用组相连缓存。对小对象进行日志化缓存会DRAM爆炸。WREN接口不支持随机写，FwSet适配到WREN中要遵循日志结构存储，将set（大于4KB）作为日志化追加的对象（关键设计）。set索引开销小。
	- 两种缓存操作：（1）**插入**。采用类似于LOC方式先插入到FwLog，如果FwLog满了，会插入到FwSet中。FwSet的插入可能会进一步导致FwSet的替换，采用GC相结合的设计，见3.2。（2）**查询**。首先采用类似于LOC方式在FwLog查询，如果找不到再hash得到对象在FwSet中对应的Set。在Set内顺序扫描找到对象。
### 3.2 垃圾回收和在线写的统一
![[Pasted image 20241105000832.png]]
当在线写，写满的时候会发生缓存替换。FairyWREN将缓存替换和垃圾回收统一起来，避免了不必要的垃圾回收写入。为此，FairyWREN新设计了驱逐操作。
- LOC
	- 当LOC满的时候，FairyWREN进行替换。驱逐时，由于segment和EU对齐，通过LRU或FIFO移除整个segment，即EU即可，完成WA=1的擦除。
- SOC（关键设计）
	- **朴素方法**。当FwSet或FwLog满的时候，需要进行垃圾回收。FairyWREN同样将其和缓存替换相结合。一个最朴素的方法是直接将末尾的EU驱逐，但冷热对象混杂会大大降低命中率。
	- **FairyWREN的“嵌套打包”**。（1）**EU选择**。FairyWREN从FwSet和FwLog中选择一个EU进行垃圾回收。（2）**Set散列**。FairyWREN会将选中的EU的所有对象哈希散列为若干Set（如果EU在FwSet中，本身就已经是若干的Set）。（3）**Set重组**。对于这些Set，FairyWREN会检索出FwLog中位于Set的所有对象。将这些Set的对象重组为一个新的Set，其中可能会逐出不必要的对象。（4）**重写与擦除**。然后将重组的Set，重新追加写入到FwSet，并擦除上述EU。
	- **如何work**？设计的最关键在于：合并了之前两个不同的过程，实现垃圾回收和缓存写入与驱逐/替换的协作。最坏的例子（如前面2.4所介绍）：LBAD的垃圾回收刚搬迁完一个Set，然后FwLog来了一个新对象后，又要马上被重写。在LBAD中，无法实现写入合并。而FairyWREN基于上述的嵌入打包，消除了很多不必要的写入。
### 3.3 KwSet的冷热对象分离
![[Pasted image 20241105000853.png]]

- **动机：** 每次从FwLog插入一个对象到FwSet，都会带来整个Set的重写。
- **冷热对象分离**。（1）**Set划分**。将KwSet划分为两个SubSet，频繁更新的热SubSet和不频繁更新的冷SubSet。冷热SubSet分别处于不同的EU中。（2）**对象识别与放置**。冷热对象的识别通过RRIP算法完成。值得注意，对于闪存缓存来说，热对象要放到冷SubSet中，因为其不会频繁被“驱逐”，会常驻于KwSet中；冷对象与之相反。这样一来，每次FwLog到FwSet的散列插入对象，只需要对KwSet中的热SubSet频繁更新即可。（3）**冷热重分类**。 但不能一直插入热SubSet，因为新插入的对象可能是热对象。因此Set每进行n次（设定的阈值）嵌套打包操作后，会进行一次全SubSet的读取（包括冷和热SubSet）。Set中的对象会重新进行合并和分类，将上述热SubSet中新插入的热对象移动到冷SubSet中。
- **讨论**。这个方法能带来接近一半的写放大优化。eg: n=5, Set=8KB，能实现40KB->24KB的写入量减少40%。但，也不是划分越多越好。而WREN只支持有限的EU（10个）。FairyWREN使用4个EU。此外，冷热分离会是的cache命中率下降，识别未必是准确的。

### 3.5 DRAM使用优化
![[Pasted image 20241105000906.png]]
- **设计：日志结构切片**。FwLog的object，FwSet的Set都是按照日志结构存储，分别需要object和Set的索引，DRAM开销很大。对日志结构存储空间进行 $2^n$ 切片可以减少n比特索引。（FwLog划分64份，FwSet划分8份）
- **朴素方法**。一种朴素的思路是一个分片用一个EU/segment，然而EU数有限。不切实际。
- **设计：共享EU/segment和碎片化问题**。所有切片共用一个sgement/EU，将DRAM中的segment分成 $2^n$ 份切片区域。各个切片将对应的区域写满后，再一次全部写到EU中。然而这会导致：部分区域可能提前写满，而其他区域没写满时就得写回EU，导致碎片化问题。
- **设计：双缓冲区**。FairyWREN采用了双缓冲区来延缓这个问题，写的快的区域，可以写入到副本缓冲区中的新区域，起到一定的“快”等”慢“的作用。等主缓冲区尽可能写满后，就写回到EU中。（效果很好，将碎片化问题限制在了1%）
- **设计：更大的Set**。此外，FairyWREN还通过增大 Set大小来减小 FwSet 索引。（作者讨论了更大的Set不会带来写放大可控，即5%）
![[Pasted image 20241107143728.png]]
最后，FairyWREN 使用的 DRAM 仅比 Kangaroo 多 19%，但后续会看到比 Kangaroo带来了12.5x写入量的减少。

## 1 背景
### 1.1 数据中心碳排放
- 预计到  2038 年数据中心占全球排放量的比例将升至 20% ,到 2050 年将升至 33% 。
- 亚马逊、谷歌、Meta、  微软都在寻求实现净零排放。
- 运营碳排放 vs 隐含碳排放：随着数据中心转向可再生能源，它们 正在迅速减少运营碳排放。因此,隐含碳现在在数据中心碳排放中占主导地位（80% 以上）。
- 隐含排放是由一次性生命周期事件产生的：器件的生产（->延长寿命），器件的功耗（->用更低功耗硬件）。
![[Pasted image 20241103095729.png]]

### 1.2 Flash Cache
![[Pasted image 20241103110832.png]]
- 存储结构与flash cache
- 全闪存和混合存储
（感觉讲的有点少，需要拓展，补充一个存储层次图讲flash cache，可能要自己画）
（1）第一张包含"寄存器"（最顶层）、"SRAM高速缓存"、"DRAM主存"、"SSD一级存储/Flash Cache"、"HDD二级存储"五层；（2）第二张包含"寄存器"（最顶层）、"SRAM高速缓存"、"DRAM主存"、"SSD全闪存存储"四层

## 2 动机
### 2.1 闪存解决碳排放
- 闪存 vs DRAM。闪存的功耗、碳密度更低。
- 闪存缓存应该尽可能高密度闪存
- 应该尽可能延长设备的使用寿命
数据中心的设备更换周期越来越长了
高密度+寿命的原因：成本、更低隐含碳成本

### 2.2闪存缓存面临的挑战
- 设备级写放大/垃圾回收写放大，作为写密集的Cache影响更为显著
根本原因在：写入和擦除的粒度不匹配是 DLWA 的根本原因。
随着闪存变得越来越密集,闪存 EU 尺寸也变得越来越大（达到千兆字节范围）。
![[Pasted image 20241103105213.png]]
- 闪存密度越高，寿命越短；想要保持寿命相同，写入速率限制的很小
![[Pasted image 20241103105426.png]]
- 传统的块设备接口lbad强制gc，带来了严重写放大。
- 现在新的设备接口wren已经推出，fairywren专为这种接口设计

### 2.3 现有方案的缺点
可能要画一个时间线：flash cache的发展
**该考虑的因素**
闪存缓存设计不是直接的
- 可持续的闪存缓存要考虑：（1）减少闲置空间，以减少无益的排放；（2）减少对象元数据的DRAM使用（达10GB）；（3）减少写入速率，以减少设备磨损速率。
- 与DRAM缓存设计思路不同：闪存缓存还必须应对闪存有限的写入耐久性，从而导致设计截然不同。低端到端写入放大（ALWA和DLWA）
- 与键值存储设计思路不同：缓存经常驱逐和删除对象。而键值存储不支持快速删除，不能很好地用于缓存。除非过度配置，通常超过缓存容量的2倍。
**现有的闪存缓存设计**
- 现有的设计无法满足：
![[Pasted image 20241103110232.png]]
每一列分别表示：闲置空间消除、最小化DRAM使用、应用级写放大、设备级写放大
闪存缓存不可避免的要频繁替换新对象，但应该要最小化应用级和设备级写入放大，以延长寿命。
![[Pasted image 20241103121048.png]]
- 日志结构缓存：为了最大限度地减少写入，采用日志结构。大量的（一个segment）顺序追加写的方式写闪存，利用DRAM索引。**缺点：** 对于较大的对象效果很好，但对于小对象来说，DRAM  索引变得过大。（例如：Flashield需要75GB DRAM来记录闪存缓存上2TB的100B对象）
- 组关联缓存：用哈希函数替换 DRAM 索引，该函数将每个对象映射到闪存上的唯一集合。**缺点：** 带来小对象的随机写，接纳一个小对象  (例如 100 B)时，它必须写入至少一个闪存页(4 KB)。后果是：（1）ALWA是40x，（2）DLWA是2x-10x。写放大 (WA) 是 ALWA 和 DLWA 的乘积。Meta 的闪存缓存仅使用 50% 的驱动器，从而增加了丢失率和碳排放。
- 分层缓存：上述的两个是一个tradeoff。kangaroo则将两者相结合，使用Klog（约5%）充当小的对象的写缓冲（日志结构，减小ALWA），使用Kset（约95%）充当主存储（哈希组关联，减少DRAM索引）。（此外还包括：选择性准入策略减少闪存写入和分区索引结构减少DRAM等技术）**缺点：** Kset还是会带来4KB随机写入，没有解决设备级写入放大放大，即DLWA的问题。==在更高密度闪存下，没什么优势？。== 
### 2.4 关键因素：LBAD接口的DLWA（GC的写放大）
Kangaroo基于传统的LBAD接口。LBAD接口屏蔽了物理层，只暴露逻辑层。Kangaroo的缓存驱逐/替换操作基于逻辑层，LBAD的垃圾回收操作基于物理层，两者互不知情。那么就会带来：GC经常会重写一些无效的数据。表现为：GC刚搬迁完，这个数据就被替换而无效了。对于密集覆写的闪存缓存来说，这个问题尤为显著。因此，作者认为垃圾回收是缓存替换的一个机会。
![[FairyWREN-LBAD-GC.png]]
![[FairyWREN-LABD-rewrite.png]]

**新的WREN接口**
- 现有的接口基于LBAD接口，简化了HDD->SSD过渡，屏蔽擦除粒度等，但会面导致很高的DLWA。
- 理想的闪存缓存接口将允许缓存控制所有写入,包括 GC,  但仍然向应用程序开发人员提供简单的抽象。
- 新的WREN接口：（1）WREN操作；（2）擦除要求（可控且整块）；（3）多个但有限活跃EU。
- 只基于WREN接口没法解决WA：（1）一个合理的尝试是：将每个Set都视为日志化存储，==允许能够在单一的EU里顺序写？但这个只是将GC从设备移动到Cache？==（2）减少EU也不可行，只有EU特别小才有效果。
（==疑惑1==，这个合理的尝试描述不清晰？什么又叫GC移动到Cache？）
（==疑惑2==，直接用kangaroo可不可行？怎么没有讨论）
![[Pasted image 20241104101957.png]]


## 4 测试
### 4.1 测试环境
![[FairyWREN-evaluate.png]]
概述一下，测试环境和建模方法如下：
- 基于CacheLib将 FairyWREN 实现为闪存缓存模块。
- 使用模拟和真实的ZNS SSD。
- 根据 Meta 和 Twitter 的生产痕迹评估  FairyWREN。
- 写入耐久性和成本预测依据 Micron 7300 NVMe U.2 TLC SSD建模。
- 使用ACT模型（ISCA'22）对CPUs, DDR4 DRAM, 和闪存的碳排放进行建模。
对比对象如下：
- 理想写入：WA为1且没有DRAM开销
- Flashield：日志结构缓存
- Kangaroo
- FairyWREN
- Physical Separation：直接把 Kangaroo 搬到 WREN 上面来，把不同的组件分离到不同的 Erase Unit 上

4.2 

### 4.3 分解测试
![[FairyWREN-test-split.png]]

结果
- FairyWREN 将闪存写入减少了 12.5 倍。
- FairyWREN 将闪存的 碳排放量减少了 33%。
- FairyWREN 在碳排放和成本方面的性能都接  近理想化的最小写入缓存。

## 5 总结
**贡献**
- 我们发现了实现更可持续的闪存缓存的机会，以及实现所面临的挑战
- 定义新的接口的模型，权衡和基本限制等
- 关键见解：（1）基于新接口的语义，统一垃圾回收和在线写；（2）大小与冷热分离

**优点和启发**
- 将高密度和寿命，通过更直观的碳排放的故事结合起来，让这个不再成为理论上的东西，而是真的有需要场景

**缺点**
- 碳排放的故事个人觉得太宏大了，对我感觉有点夸大
- 据说创新性不够？再看看
- LBAD的GC DLWA问题论文中没有讲清楚，我去看了作者的presentation，在presentation的PPT里，就讲明白了
- 基于前序工作改进，写作时将自己的设计和前序工作的设计混在一起叙述，不对比阅读就不知道这个工作独到的地方在哪

**展望**
- 好奇驱逐策略是什么？以前LBAD接口需要GC，按page粒度驱逐，cache miss概率很低？以整个EU粒度驱逐，会不会增大cache miss的可能？cache是为了读加速+覆盖写？难道保证整个EU中的读局部性是一样的吗？读局部性 和 写局部性是有所不一样的？

## 拓展

**数据中心的碳排放**
![[Pasted image 20241102095613.png]]


**为什么不使用全闪存存储**：全闪存存储 VS 闪存缓存混合存储
尽管全闪存存储（all-flash storage）提供了更快的访问速度，但它通常不被用于大规模的缓存系统或作为唯一的存储介质，主要有以下几个原因：
1. 成本较高：虽然闪存（Flash）比 DRAM 更便宜，但它仍然比传统的硬盘（HDD）昂贵得多。在需要存储大量数据（例如 PB 级）时，全部使用闪存的成本会很高。企业通常会选择性价比更高的分层存储方案，将热数据放在闪存中，而冷数据（不常访问的数据）则保存在硬盘中。
2. 寿命有限：闪存有写入寿命限制，每个单元只能承受有限次数的写入和擦除。对于一些写入频率较高的应用场景，过度使用全闪存可能会导致较快的磨损，从而缩短闪存的寿命。这就是为什么很多缓存系统会通过将部分频繁写入的缓存数据存储在 DRAM 中来保护闪存。
3. 延迟和吞吐瓶颈：全闪存系统虽快，但 DRAM 的延迟比闪存低一个数量级。因此，在需要极低延迟的应用中，仅依靠闪存仍可能无法满足性能需求。结合 DRAM 和闪存可以更有效地实现低延迟的缓存和数据处理。
4. 数据管理的复杂性：混合使用 DRAM、闪存和硬盘可以更好地满足不同类型数据的存储需求。将数据分层存储，并将热数据缓存到 DRAM 或闪存，而冷数据存储在硬盘中，可以更高效地管理成本和性能，同时实现良好的数据访问效率。
因此，分层存储系统——将闪存与DRAM和硬盘结合使用——通常被认为是成本效益最高、性能最优的存储架构。

## reference
- <a href="https://mp.weixin.qq.com/s/0g1jBn9SdE4QwygKx2qwQQ">【论文解读】数据中心节能减排：可持续的闪存缓存设计 FairyWREN (OSDI'24)</a>
- <a href="https://www.zhihu.com/question/649626302/answer/3596509565"> 2024年操作系统设计与实现研讨会（OSDI）有哪些值得关注的文章？--FairyWREN </a>
- <a href="https://zhuanlan.zhihu.com/p/708037149"> OSDI 2024 论文评述 Day 3 Session 9: Data Management | IPADS-SYS </a>