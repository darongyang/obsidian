## 1 背景
- SSD设备的内存越来越大，如何使用少量的内存来存储L2P表？

## 2 动机
- **L2P卸载**。现有的DFTL/TPFTL工作利用局部性原理实现L2P表卸载。使用二级L2P表，只用少量的DRAM缓存近期的L2P表项。**缺点**：DRAM未命中时，有闪存上的Double Read。
- **学习型索引**。LeaFTL利用顺序写的映射线性的特点，实现满足线性关系（y=ax+b，y为ppa，x为lba）的表项合并。**缺点：** 随机读准确率低、无法发挥写并行、模型训练开销大、==Double和Triple Read==。


## 3 设计

- ==总体上使用了L2P缓存和？==

- 为每个模型设置标志位，预测前就知道这个模型是否这个正确

- ==线性模型的就地更新==

- 利用并行特点，重排地址字段，构造连续的虚拟物理地址

- ==基于组的分配==

- 模型重训练时机发生在：顺序写、==垃圾回收（？）==


## QA
Q1：现在的顺序写，出于内部并行的原因，其分配的物理地址也不是严格连续的，不用地址重映射，LeaFTL原来是怎么做的？
Q2：判断模型预测的是否准确的依据是什么？怎么判断出来的？需要进行什么校验？位图滤波器如何设置的？
Q3：LearnedFTL架构和LeaFTL有什么不同？
Q4：模型训练的开销多大？顺序写的时候进行模型训练开销多大？如何识别顺序写还是随机写？