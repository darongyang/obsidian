提问同学：论文是场景是单卡还是多卡？（回答单卡）现在训练都是多卡？既然如此的场景论文的适用吗？为什么论文需要基于GPU仿真平台？而不是在真实的机器上直接运行？
提问同学：在线的优势来源于离线的分析，想请问作者是否有对离线的开销进行讨论？每次训练一个模型都进行一次离线分析，成本会不会较大？
提问老师：多卡的情况下会有一致性问题吗？预取不能解决带，闲置情况有多大呢？分析为什么能分析模型完成？
副点评老师：提一下MICRO会议的简介，介绍这个会议是CCF收录的A会，是体系结构的顶会，让跨领域的老师同学对工作整体把控有个比较清楚的了解。G10这样的训练会不会影响的模型精度或者训练效果？
主点评老师：GPU显存的拓展这个研究方向很有意义；有没有深入看对比文献，有没有做复现？；有没有对内存扩展之类有了解，比如CXL

在确定论文后，我投入了大量时间进行内容准备。（1）精读论文，提炼核心。 我首先反复精读了G10论文，并参考了第41期总结中方老师关于“抓住论文的‘核’”的指导，不再完全按照论文的章节结构来准备，而是尝试跳出作者的叙述基调，从问题、动机、设计、实现和评估五个核心要素出发，重新梳理论文的逻辑。尤其关注G10解决的核心问题、提出的关键机制以及其在实际应用中的优势。（2）背景知识拓展。针对论文中涉及的DNN训练流程、GPU内存体系、SSD存储技术等概念，我查阅了大量相关资料进行补充学习。汲取第33期总结中“汇报的背景讲述不够清晰”、“重要且核心的概念，如云本地盘、部署密度等核心概念做进一步的拓展和衍生”的教训，我特别注意了对这些关键概念的清晰解释，力求让非专业背景的听众也能理解。例如，在PPT中增加了DNN训练数据流程的图示，并对Tensor Offload等概念进行了解释。（3）思考质疑点与应对。 在准备过程中，我主动模拟听众可能提出的问题，并预设答案。例如，G10与现有异构存储方案（如FlashNeuron, DeepUM+）的对比优势是什么？智能张量迁移的具体策略如何实现？这些思考有助于我在汇报时更好地应对提问，也反映了第33期总结中关于“论文解决方案的创新点提炼不到位”的反思。（3）逻辑串联与故事线。 我尝试将论文内容组织成一个有逻辑的故事线，从问题出发，引出动机，再逐步介绍G10的设计与实现，最后通过实验评估来验证其有效性。这样的组织方式旨在让汇报更具连贯性和说服力。